#!/usr/bin/env python


__author__ = 'Leland Taylor'
__date__ = '2020-07-03'
__version__ = '0.0.1'

import argparse
#import csv
import os
import random
import numpy as np
import pandas as pd
import scanpy as sc
import plotnine as plt9
from kneed import KneeLocator
from distutils.version import LooseVersion
from scipy.interpolate import UnivariateSpline

# To resolve strange TclError for interactive job
import matplotlib
matplotlib.use('Agg')  # Agg for png and pdf for pdf

# Set seed for reproducibility
seed_value = 0
# 0. Set `PYTHONHASHSEED` environment variable at a fixed value
os.environ['PYTHONHASHSEED'] = str(seed_value)
# 1. Set `python` built-in pseudo-random generator at a fixed value
random.seed(seed_value)
# 2. Set `numpy` pseudo-random generator at a fixed value
np.random.seed(seed_value)

# Set valid methods for estimators
valid_methods = [
    'dropletutils::barcoderanks::inflection',
    'dropletutils::barcoderanks::knee',
    'kneedle::spline=None',
    'kneedle::spline=interp1d',
    'kneedle::spline=polynomial',
    'expected',
    'expected_umicutoff'
]


def comma_labels(x_list):
    """Change list of int to comma format."""
    result = []
    for x in x_list:
        result.append(format(int(x), ','))
    return(result)


def estimate_cutoffs_plot(
    output_file,
    df_plt,
    df_estimate_ncells,
    df_fit=None,
    scale_x_log10=False,
    save_plot=True,
    add_text=False
):
    """Plot UMI counts by sorted cell barcodes."""
    if min(df_plt['umi_counts']) <= 0:
        fix_log_scale = min(df_plt['umi_counts']) + 1
        df_plt['umi_counts'] = df_plt['umi_counts'] + fix_log_scale
    if add_text:
        df_estimate_ncells['add_text_y'] = np.random.randint(
            low=df_plt['umi_counts'].min()-25,
            high=df_plt['umi_counts'].max()-25,
            size=df_estimate_ncells.shape[0]
        )
    gplt = plt9.ggplot()
    gplt = gplt + plt9.theme_bw()
    if len(df_plt) <= 50000:
        gplt = gplt + plt9.geom_point(
            mapping=plt9.aes(x='barcode', y='umi_counts'),
            data=df_plt,
            alpha=0.05,
            size=0.1
        )
    else:
        gplt = gplt + plt9.geom_line(
            mapping=plt9.aes(x='barcode', y='umi_counts'),
            data=df_plt,
            alpha=0.25,
            size=0.75,
            color='grey'
        )
    gplt = gplt + plt9.geom_vline(
        mapping=plt9.aes(xintercept='n_cells', color='method'),
        data=df_estimate_ncells,
        alpha=0.75,
        linetype='dashdot'
    )
    if add_text:
        gplt = gplt + plt9.geom_text(
            mapping=plt9.aes(
                x='n_cells',
                y='add_text_y',
                label='n_cells',
                color='method'
            ),
            data=df_estimate_ncells,
            alpha=0.75
        )
    gplt = gplt + plt9.scale_color_brewer(
        palette='Dark2',
        type='qual'
    )
    if scale_x_log10:
        gplt = gplt + plt9.scale_x_continuous(
            trans='log10',
            labels=comma_labels,
            minor_breaks=0
        )
    else:
        gplt = gplt + plt9.scale_x_continuous(
            labels=comma_labels,
            minor_breaks=0
        )
    gplt = gplt + plt9.scale_y_continuous(
        trans='log10',
        labels=comma_labels,
        minor_breaks=0
    )
    gplt = gplt + plt9.labs(
        title='',
        y='UMI counts',
        x='Barcode index, sorted by UMI count',
        color='Cutoff'
    )
    # Add the fit of the droplet utils model
    if df_fit:
        gplt = gplt + plt9.geom_line(
            mapping=plt9.aes(x='x', y='y'),
            data=df_fit,
            alpha=1,
            color='yellow'
        )
    if save_plot:
        gplt.save(
            '{}.png'.format(output_file),
            dpi=300,
            width=5,
            height=4
        )
    return gplt


def dropletutils_cutoff(df_analysis):
    """Calculate the knee and inflection point as in DropletUtils."""
    # Calculate the knee and inflection point as in DropletUtils::barcodeRanks
    # https://github.com/MarioniLab/DropletUtils/blob/master/R/barcodeRanks.R
    # Numerical differentiation to identify bounds for spline fitting.
    # The upper/lower bounds are defined at the plateau and inflection.
    #
    # The lower bound on the total UMI count, at or below which all barcodes
    # are assumed to correspond to empty droplets
    # df_analysis = df.loc[df['umi_counts'] >= lower_bound, :]
    if min(df_analysis['umi_counts']) <= 0:
        fix_log_scale = min(df_analysis['umi_counts']) + 1
        df_analysis['umi_counts'] = df_analysis['umi_counts'] + fix_log_scale
    d1n = np.diff(
        np.log10(df_analysis['umi_counts'])
    )/np.diff(np.log10(df_analysis['barcode']))
    # NOTE: these are the indexes of the edge of the plot
    right_edge = np.argmin(d1n)
    left_edge = np.argmax(d1n[0:right_edge])

    # We restrict to this region, thereby simplifying the shape of the curve.
    # This allows us to get a decent fit with low df for stable differentiation
    # Smoothing to avoid error multiplication upon differentiation.
    # Minimizing the signed curvature and returning the total for the knee
    # point
    x = np.log10(
        df_analysis.iloc[left_edge:right_edge, :]['barcode'].values
    )
    y = np.log10(
        df_analysis.iloc[left_edge:right_edge, :]['umi_counts'].values
    )
    dropletutils_fit = UnivariateSpline(x, y)
    fit1 = dropletutils_fit.derivative(n=1)
    fit2 = dropletutils_fit.derivative(n=2)
    curvature = fit1(x) / np.power(1 + np.power(fit2(x), 2), 1.5)
    dropletutils_knee = 10 ** y[np.argmin(curvature)]
    dropletutils_inflection = df_analysis.iloc[right_edge, :]['umi_counts']
    dropletutils_knee_ncells = 10 ** x[np.argmin(curvature)]
    dropletutils_inflection_ncells = df_analysis.iloc[right_edge, :]['barcode']

    result = [
        {
            'method': 'dropletutils::barcoderanks::knee',
            'umi_counts_cutoff': dropletutils_knee,
            'n_cells': int(dropletutils_knee_ncells)
        },
        {
            'method': 'dropletutils::barcoderanks::inflection',
            'umi_counts_cutoff': dropletutils_inflection,
            'n_cells': int(dropletutils_inflection_ncells)
        }
    ]

    return right_edge, left_edge, result


def kneedle_cutoff(df_analysis, verbose=True):
    """Get kneedle estimate for what is a cell."""
    results = []
    # Get kneedle estimate using raw data OR fit smoothing spline. Also
    # maximize sensitivity.
    # NOTE: Much better estimates with kneedle (that is similar to cellranger3)
    # if this is done the original value space - not log space.
    kneedle_dict = {}
    for fit in [None, 'interp1d', 'polynomial']:
        key = 'kneedle::spline={}'.format(fit)
        sensitivity = 5000
        while True:
            if fit:
                kneedle_dict[key] = KneeLocator(
                    df_analysis['barcode'].values,
                    df_analysis['umi_counts'].values,
                    curve='convex',
                    direction='decreasing',
                    S=sensitivity,
                    interp_method=fit
                )
            else:
                kneedle_dict[key] = KneeLocator(
                    df_analysis['barcode'].values,
                    df_analysis['umi_counts'].values,
                    curve='convex',
                    direction='decreasing',
                    S=sensitivity
                )
            if kneedle_dict[key].knee is None:
                sensitivity -= 100
            else:
                if verbose:
                    print('S:\t{}\nknee:\t{}\nelbow:\t{}'.format(
                        sensitivity,
                        round(kneedle_dict[key].knee, 3),
                        round(kneedle_dict[key].elbow, 3)
                    ))
                results.append({
                    'method': key,
                    'umi_counts_cutoff': df_analysis.loc[
                        df_analysis['barcode'].values == int(
                            kneedle_dict[key].knee
                        ),
                        'umi_counts'
                    ].values[0],
                    'n_cells': int(kneedle_dict[key].knee),
                    'sensitivity': sensitivity
                    # 'elbow': 10 ** kneedle_dict[key].elbow  # same as knee
                })
                break
    return results


def get_final_estimates(
    df_estimates,
    method='dropletutils::barcoderanks::inflection',
    subtract_n_factor=0,
    verbose=False
):
    # Check to see if list. If list then it must be three values:
    # (1) estimator 1
    # (2) estimator 2
    # (3) factor to split the difference between the estimates
    split_factor = 1.0

    if not isinstance(method, str):     # assume it is a list
        if len(method) == 1:
            pass
        elif len(method) == 3:
            split_factor = float(method.pop())
        else:
            raise Exception(
                'Error in method ({}). \
                Should be:\testimate1,estimate2,split_factor'.format(
                    ','.join(method)
                )
            )
    else:
        method = [method]

    # Check the methods
    apply_subtract_factor = True
    for met in method:
        if met not in valid_methods:
            raise Exception('Invalid method:\t{}.'.format(met))
        # Do not apply the subtract factor if we have an "expected" method
        if met in ['expected', 'expected_umicutoff']:
            apply_subtract_factor = False

    # Now calculate the final estimate
    estimates = []
    for met in method:
        filt = df_estimates['method'] == met
        estimates.append(df_estimates.loc[filt, 'n_cells'].values[0])
    if len(estimates) == 1:
        estimated_n = estimates[0]
    elif len(estimates) == 2:
        estimated_n = abs(estimates[0] - estimates[1]) * split_factor
        estimated_n += min(estimates)
    else:
        raise Exception('Error in computing estimate.')

    # If method not an exact one, then apply the subtract_factor
    if apply_subtract_factor:
        estimated_n -= subtract_n_factor

    if verbose:
        pass

    return int(estimated_n), ','.join(method)


def main():
    """Run CLI."""
    parser = argparse.ArgumentParser(
        description="""
            Estimates cutoffs for cellbender remove background from total UMI
            counts. NOTE: different cutoff estimators work better on different
            tissues/protocols that have slightly different UMI count plots.
            """
    )
    parser.add_argument(
        '-v', '--version',
        action='version',
        version='%(prog)s {version}'.format(version=__version__)
    )
    parser.add_argument(
        '-txd', '--tenxdata_path',
        action='store',
        dest='txd',
        required=True,
        help='Path to 10x data.'
    )
    # Let the user set the expected number of cells / droplets
    parser.add_argument(
        '--expected_ncells',
        action='store',
        dest='expected_ncells',
        default=0,
        type=int,
        help='Expected number of cells. If != 0, this number of cells \
            will be used for expected_cells.txt. (default: %(default)s).'
    )
    # Let the user set the expected number of cells / droplets
    parser.add_argument(
        '--expected_nemptydroplets',
        action='store',
        dest='expected_ndroplets',
        default=0,
        type=int,
        help='Expected total number of empty droplets. If != 0, this number of \
            will be used for total_droplets_included.txt. \
            (default: %(default)s).'
    )
    # Let the user set expected number of droplets based on UMI counts
    parser.add_argument(
        '--expected_nemptydroplets_umi_cutoff',
        action='store',
        dest='expected_ndroplets_umicutoff',
        default=0,
        type=int,
        help='Set expected number of empty droplets to droplets with UMI \
            cutoffs below this value. \
            If != 0 and expected_total_ndroplets == 0, the corresponding UMI \
            barcode ranks will be used for total_droplets_included.txt. \
            (default: %(default)s).'
    )
    # Estimate the expected number of cells
    parser.add_argument(
        '--method_estimate_ncells',
        action='store',
        dest='method_ncells',
        default='dropletutils::barcoderanks::inflection',
        help='Method to use to estimate number of cells if \
            expected_ncells == 0. Valid options = [{}]. \
            (default: %(default)s)'.format(','.join(valid_methods))
    )
    parser.add_argument(
        '--method_estimate_nemptydroplets',
        action='store',
        dest='method_ndroplets',
        default='dropletutils::barcoderanks::knee',
        help='Method to use to estimate total number of droplets if \
            total_ndroplets == 0. Valid options = [{}]. \
            One can also calculate the difference between two metrics \
            (default: %(default)s)'.format(','.join(valid_methods))
    )
    parser.add_argument(
        '--lower_bound_umis_estimate_ncells',
        action='store',
        dest='lb_estimated_ncells',
        default=1000,
        type=int,
        help='The lower bound on the total UMI count at or below which all \
            barcodes are assumed to correspond to empty droplets (for \
            estimating expected ncells). \
            (default: %(default)s)'
    )
    parser.add_argument(
        '--upper_bound_umis_estimate_nemptydroplets',
        action='store',
        dest='ub_estimated_ndroplets',
        default=250,
        type=int,
        help='The upper bound on the total UMI count used to estimate cells \
            with ambient RNA that will be included in cellbender to \
            estimate the background. \
            (default: %(default)s)'
    )
    parser.add_argument(
        '--lower_bound_umis_estimate_nemptydroplets',
        action='store',
        dest='lb_estimated_ndroplets',
        default=10,
        type=int,
        help='The lower bound on the total UMI count used to estimate cells \
            with ambient RNA that will be included in cellbender to \
            estimate the background. \
            (default: %(default)s)'
    )
    parser.add_argument(
        '--estimate_nemptydroplets_add_umifactor',
        action='store',
        dest='add_umifactor_estimated_ndroplets',
        default=0,
        type=int,
        help='Add this number from the estimated UMI cutoff \
            to get the final total_ndroplets. Adding shifts the cutoff on the \
            UMI curve to the left. This option only does something if \
            expected_nemptydroplets and expected_nemptydroplets_umi_cutoff \
            are 0. If the final value is outside the range of \
            ub_estimated_ndroplets, then it is set to ub_estimated_ndroplets. \
            (default: %(default)s)'
    )
    parser.add_argument(
        '--estimate_nemptydroplets_subtract_dropletfactor',
        action='store',
        dest='subtract_dropletfactor_estimated_ndroplets',
        default=0,
        type=int,
        help='Subtract this number from the estimated count cutoff \
            to get the final total_ndroplets. Subtract shifts the cutoff on \
            the UMI curve to the left. This option only does something if \
            expected_nemptydroplets and expected_nemptydroplets_umi_cutoff \
            are 0. (default: %(default)s)'
    )
    parser.add_argument(
        '--estimate_nemptydroplets_min_nemptydroplets',
        action='store',
        dest='min_ndroplets',
        default=0,
        type=int,
        help='Minimum value for empty drops cutoff. \
            If estimate <= this value, then we set the threshold to this \
            value. (default: %(default)s)'
    )
    parser.add_argument(
        '-of', '--output_file',
        action='store',
        dest='of',
        default='adata',
        help='Basename of output files, assuming output in current \
            working directory. \
            (default: %(default)s)'
    )

    options = parser.parse_args()

    # Get compression opts for pandas
    compression_opts = 'gzip'
    if LooseVersion(pd.__version__) > '1.0.0':
        compression_opts = dict(method='gzip', compresslevel=9)

    # Get clean names
    method_ncells = options.method_ncells.split(',')
    method_ndroplets = options.method_ndroplets.split(',')
    expected_ndroplets_umicutoff = options.expected_ndroplets_umicutoff
    lb_estimated_ncells = options.lb_estimated_ncells
    lb_estimated_ndroplets = options.lb_estimated_ndroplets
    ub_estimated_ndroplets = options.ub_estimated_ndroplets
    add_umifactor_estimated_ndroplets = (
        options.add_umifactor_estimated_ndroplets
    )
    subtract_dropletfactor_estimated_ndroplets = (
        options.subtract_dropletfactor_estimated_ndroplets
    )
    min_ndroplets = options.min_ndroplets
    output_file = options.of
    verbose = True

    # Check for something wonky
    if (
        add_umifactor_estimated_ndroplets != 0
    ) and (
        subtract_dropletfactor_estimated_ndroplets != 0
    ):
        raise Exception('Error in computing estimate.')

    # Load single cell file
    file = options.txd
    adata = sc.read_10x_mtx(
        path=file,
        # var_names='gene_symbols',
        var_names='gene_ids',
        make_unique=False
    )

    # Make the umi dataframe
    df = pd.DataFrame({
        'umi_counts': np.sort(
            (np.array(adata.X.sum(axis=1))).flatten()
        )[::-1]
    })
    df['barcode'] = df.index + 1

    # Make an analysis df using lower bound
    df_analysis = df.loc[df['umi_counts'] >= lb_estimated_ncells, :]
    df_analysis = df_analysis.reset_index(drop=True)
    # Get dropletutils estimates
    right_edge, left_edge, result_dropletutils = dropletutils_cutoff(
        df_analysis
    )
    # Get kneedle estimates
    result_kneedle = kneedle_cutoff(df_analysis, verbose=False)
    # Save the results to a list we will turn into a pandas matrix
    cell_estimate_outdict = []
    for i in result_dropletutils:
        cell_estimate_outdict.append(i)
    for i in result_kneedle:
        cell_estimate_outdict.append(i)

    # Set expected number of cells if we have some
    if options.expected_ncells != 0:
        # NOTE: with specific esimates, we should use the raw df
        method_ncells = 'expected'
        cell_estimate_outdict.append({
            'method': 'expected',
            'umi_counts_cutoff': df['umi_counts'][options.expected_ncells],
            'n_cells': options.expected_ncells
        })
        # If we have expected number of cells, then go ahead and
        # also estimate like CellRanger2.
        # Assumes a ~10-fold range of library sizes for real cells and
        # estimates this range using the expected number of cells.
        # https://scrnaseq-course.cog.sanger.ac.uk/website/processing-raw-scrna-seq-data.html
        # 99th percentile of top n_cells divided by 10
        #
        # NOTE: with specific esimates, we should use the raw df
        cellranger_expected_knee = df['umi_counts'][
            round(0.01*options.expected_ncells)
        ]/10
        cell_estimate_outdict.append({
            'method': 'cellrangerv2::expected',
            'umi_counts_cutoff': cellranger_expected_knee,
            'n_cells': (df['umi_counts'] >= cellranger_expected_knee).sum()
        })

    # Make a dataframe of all of the different knee calculations
    # NOTE: here knee is the number of cells that would be kept at that
    # threshold
    df_estimate_ncells = pd.DataFrame(cell_estimate_outdict)
    # Add the fit of the droplet utils model
    # df_fit = pd.DataFrame({
    #     'y': 10 ** dropletutils_fit(x),
    #     'x': 10 ** x
    # })

    # Get the final number of estimated cells
    estimated_ncells, estimated_ncells_method = get_final_estimates(
        df_estimates=df_estimate_ncells,
        method=method_ncells,
        subtract_n_factor=0,
        verbose=verbose
    )
    # Add the final estimate to the output dict
    cell_estimate_outdict.append({
        'method': 'estimated_ncells',
        'umi_counts_cutoff': 0,
        'n_cells': estimated_ncells
    })
    df_estimate_ncells = pd.DataFrame(cell_estimate_outdict)

    # Save all of our estimates
    df_estimate_ncells.to_csv(
        '{}-cell_estimate_cutoff.tsv.gz'.format(output_file),
        sep='\t',
        compression=compression_opts,
        index=False,
        header=True
    )
    # Save the final estimates
    with open('{}-expected_cells.txt'.format(output_file), 'w') as f:
        f.write(str(int(estimated_ncells)))

    # Make a plot of the different cutoffs
    _ = estimate_cutoffs_plot(
        '{}-cell_estimate_cutoffs-zoomed'.format(output_file),
        df_analysis,
        df_estimate_ncells,
        # df_fit=df_fit,
        scale_x_log10=False
    )
    _ = estimate_cutoffs_plot(
        '{}-cell_estimate_cutoffs'.format(output_file),
        df,
        df_estimate_ncells,
        # df_fit=df_fit,
        scale_x_log10=True
    )

    # Run a similar proceedure but for total-droplets-included.
    # ...these will be the lower bound of the droplets used to estimate the
    # background signals
    # Make an analysis df using lower bound
    df_analysis = df.loc[df['umi_counts'] >= lb_estimated_ndroplets, :]
    df_analysis = df_analysis.loc[
        df_analysis['umi_counts'] <= ub_estimated_ndroplets,
        :
    ]
    df_analysis = df_analysis.reset_index(drop=True)
    # Get dropletutils estimates
    right_edge, left_edge, result_dropletutils = dropletutils_cutoff(
        df_analysis
    )
    # Get kneedle estimates
    result_kneedle = kneedle_cutoff(df_analysis, verbose=False)
    # Save the results to a list we will turn into a pandas matrix
    total_droplets_estimate_outdict = []
    for i in result_dropletutils:
        total_droplets_estimate_outdict.append(i)
    for i in result_kneedle:
        total_droplets_estimate_outdict.append(i)

    # If we have an expected total number of droplets use that.
    if options.expected_ndroplets != 0:
        # NOTE: with specific esimates, we should use the raw df
        method_ndroplets = 'expected'
        total_droplets_estimate_outdict.append({
            'method': 'expected',
            'umi_counts_cutoff': df['umi_counts'][options.expected_ndroplets],
            'n_cells': options.expected_ndroplets
        })
    # If we have expected total number of droplets based on total UMIs use that
    if expected_ndroplets_umicutoff != 0:
        # NOTE: with specific esimates, we should use the raw df
        total_droplets_estimate_outdict.append({
            'method': 'expected_umicutoff',
            'umi_counts_cutoff': expected_ndroplets_umicutoff,
            'n_cells': df.loc[
                df['umi_counts'] <= expected_ndroplets_umicutoff,
                'barcode'
            ].min()
        })
        # Never over-ride expected_ndroplets
        if options.expected_ndroplets == 0:
            method_ndroplets = 'expected_umicutoff'

    # Make a dataframe of all of the estimates
    df_estimate_ndroplets = pd.DataFrame(total_droplets_estimate_outdict)

    # Now, get the final number of estimated droplets
    estimated_ndroplets, estimated_ndroplets_method = get_final_estimates(
        df_estimates=df_estimate_ndroplets,
        method=method_ndroplets,
        subtract_n_factor=subtract_dropletfactor_estimated_ndroplets,
        verbose=verbose
    )
    # We have one last edit and that is if the user has told us to subtract
    # something based on umis
    if estimated_ndroplets_method not in ['expected', 'expected_umicutoff']:
        if add_umifactor_estimated_ndroplets:
            estimated_ndroplets_umicutoff = df.loc[
                df['barcode'] == estimated_ndroplets,
                'umi_counts'
            ].values[0]
            # if (
            #     estimated_ndroplets_umicutoff >= lb_estimated_ndroplets - 10
            # ) and (
            #     estimated_ndroplets_umicutoff <= lb_estimated_ndroplets + 10
            # ):
            estimated_ndroplets_umicutoff += add_umifactor_estimated_ndroplets
            estimated_ndroplets_umicutoff = max(
                estimated_ndroplets_umicutoff,
                ub_estimated_ndroplets
            )
            estimated_ndroplets = df.loc[
                df['umi_counts'] == estimated_ndroplets_umicutoff,
                'barcode'
            ].values[0]
    # If the estimated ndroplets is less than the user specified min, then set
    # to the user specified min.
    if (estimated_ndroplets != 0) and (estimated_ndroplets < min_ndroplets):
        estimated_ndroplets = min_ndroplets

    # Add the final estimate to the output
    total_droplets_estimate_outdict.append({
        'method': 'estimated_ndroplets',
        'umi_counts_cutoff': 0,
        'n_cells': estimated_ndroplets
    })
    df_estimate_ndroplets = pd.DataFrame(total_droplets_estimate_outdict)
    # Save all of our estimates
    df_estimate_ndroplets.to_csv(
        '{}-total_droplets_cutoff.tsv.gz'.format(output_file),
        sep='\t',
        compression=compression_opts,
        index=False,
        header=True
    )
    # Save total_droplets_included
    with open('{}-total_droplets_included.txt'.format(output_file), 'w') as f:
        f.write(str(int(estimated_ndroplets)))

    # Make a plot of the different cutoffs
    _ = estimate_cutoffs_plot(
        '{}-total_drops_estimate_cutoffs-zoomed'.format(output_file),
        df_analysis,
        pd.DataFrame(total_droplets_estimate_outdict),
        # df_fit=df_fit,
        scale_x_log10=False,
        save_plot=True
    )
    _ = estimate_cutoffs_plot(
        '{}-total_drops_estimate_cutoffs'.format(output_file),
        df,
        pd.DataFrame(total_droplets_estimate_outdict),
        # df_fit=df_fit,
        scale_x_log10=True
    )

    # Plot the final estimates togher
    final_cutoffs = []
    final_cutoffs.append({
        'method': 'Estimated expected # cells',
        'umi_counts_cutoff': 0,
        'n_cells': estimated_ncells
    })
    final_cutoffs.append({
        'method': 'Estimated total # droplets',
        'umi_counts_cutoff': 0,
        'n_cells': estimated_ndroplets
    })
    # print(final_cutoffs)
    # Optinally zoom in the final estimates
    # df_plt = df.loc[df['barcode'] <= total_droplets_cutoff_ncells + 100, :]
    df_plt = df.loc[df['umi_counts'] >= 1, :]
    _ = estimate_cutoffs_plot(
        '{}-final_estimates'.format(output_file),
        df_plt,
        pd.DataFrame(final_cutoffs),
        # df_fit=df_fit,
        scale_x_log10=False,
        save_plot=True,
        add_text=True
    )
    _ = estimate_cutoffs_plot(
        '{}-final_estimates-scale_x_log10'.format(output_file),
        df_plt,
        pd.DataFrame(final_cutoffs),
        # df_fit=df_fit,
        scale_x_log10=True,
        save_plot=True,
        add_text=True
    )


if __name__ == '__main__':
    main()
